{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\envs\\linkedin\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\envs\\linkedin\\lib\\site-packages (from beautifulsoup4) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "# import ipython\n",
    "import time\n",
    "import parsel\n",
    "import csv\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import web driver\n",
    "from selenium import webdriver\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dfr = pd.read_csv('results_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openpyxl.load_workbook(filename='results_file.xlsx')\n",
    "results = res.worksheets[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('leads.csv',index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ankur</td>\n",
       "      <td>Jain</td>\n",
       "      <td>Rubrik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shibin</td>\n",
       "      <td>Nambiar</td>\n",
       "      <td>Rubrik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harsh</td>\n",
       "      <td>Salekar</td>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Udayan</td>\n",
       "      <td>Birajdar</td>\n",
       "      <td>Santa Clara University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tanmay</td>\n",
       "      <td>Wagh</td>\n",
       "      <td>Santa Clara University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jayesh</td>\n",
       "      <td>Patil</td>\n",
       "      <td>Ancestry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prajakta</td>\n",
       "      <td>Pingale</td>\n",
       "      <td>Santa Clara University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hasan</td>\n",
       "      <td>Khan</td>\n",
       "      <td>Grabango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sherry</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>Levi Strauss &amp; Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Daria</td>\n",
       "      <td>Saha</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FirstName  LastName                 Company\n",
       "ID                                            \n",
       "1      Ankur      Jain                  Rubrik\n",
       "2     Shibin   Nambiar                  Rubrik\n",
       "3      Harsh   Salekar                 Infosys\n",
       "4     Udayan  Birajdar  Santa Clara University\n",
       "5     Tanmay      Wagh  Santa Clara University\n",
       "6     jayesh     Patil                Ancestry\n",
       "7   Prajakta   Pingale  Santa Clara University\n",
       "8      Hasan      Khan                Grabango\n",
       "9     Sherry     Zhang      Levi Strauss & Co.\n",
       "10     Daria      Saha         Sequoia Capital"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name']=df['FirstName']+' '+df['LastName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Company</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ankur</td>\n",
       "      <td>Jain</td>\n",
       "      <td>Rubrik</td>\n",
       "      <td>Ankur Jain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shibin</td>\n",
       "      <td>Nambiar</td>\n",
       "      <td>Rubrik</td>\n",
       "      <td>Shibin Nambiar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harsh</td>\n",
       "      <td>Salekar</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>Harsh Salekar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Udayan</td>\n",
       "      <td>Birajdar</td>\n",
       "      <td>Santa Clara University</td>\n",
       "      <td>Udayan Birajdar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tanmay</td>\n",
       "      <td>Wagh</td>\n",
       "      <td>Santa Clara University</td>\n",
       "      <td>Tanmay Wagh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FirstName  LastName                 Company             Name\n",
       "ID                                                             \n",
       "1      Ankur      Jain                  Rubrik       Ankur Jain\n",
       "2     Shibin   Nambiar                  Rubrik   Shibin Nambiar\n",
       "3      Harsh   Salekar                 Infosys    Harsh Salekar\n",
       "4     Udayan  Birajdar  Santa Clara University  Udayan Birajdar\n",
       "5     Tanmay      Wagh  Santa Clara University      Tanmay Wagh"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=df[\"Name\"].iloc[:].values\n",
    "companies=df[\"Company\"].iloc[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query to search: site:linkedin.com/in/ Ankur Jain Rubrik\n",
      "LinkedIn URL: https://www.linkedin.com/in/ankur-jain-81634914\n",
      "Query to search: site:linkedin.com/in/ Shibin Nambiar Rubrik\n",
      "LinkedIn URL: https://www.linkedin.com/in/shibinnambiar\n",
      "Query to search: site:linkedin.com/in/ Harsh Salekar Infosys\n",
      "LinkedIn URL: https://in.linkedin.com/in/harsh-salekar-75923a147\n",
      "Query to search: site:linkedin.com/in/ Udayan Birajdar Santa Clara University\n",
      "LinkedIn URL: https://www.linkedin.com/in/udayanbirajdar\n",
      "Query to search: site:linkedin.com/in/ Tanmay Wagh Santa Clara University\n",
      "LinkedIn URL: https://www.linkedin.com/in/tanmaywagh30\n",
      "Query to search: site:linkedin.com/in/ jayesh Patil Ancestry\n",
      "LinkedIn URL: https://www.linkedin.com/in/j-patil\n",
      "Query to search: site:linkedin.com/in/ Prajakta Pingale Santa Clara University\n",
      "LinkedIn URL: https://www.linkedin.com/in/prajakta-pingale\n",
      "Query to search: site:linkedin.com/in/ Hasan Khan Grabango\n",
      "LinkedIn URL: https://www.linkedin.com/in/hasan-khan-8296b2b2\n",
      "Query to search: site:linkedin.com/in/ Sherry Zhang Levi Strauss & Co.\n",
      "LinkedIn URL: https://www.linkedin.com/in/sherry-zhang-6a319785\n",
      "Query to search: site:linkedin.com/in/ Daria Saha Sequoia Capital\n",
      "LinkedIn URL: https://www.linkedin.com/in/daria-saha-62095085\n",
      "Query to search: site:linkedin.com/in/ Xiaolu Zhao IDEAS\n",
      "LinkedIn URL: https://www.linkedin.com/in/xiaolu-lucy-zhao-a6071742\n"
     ]
    }
   ],
   "source": [
    "# to search \n",
    "col_name=1\n",
    "col_company_name=8\n",
    "col_person_link=11\n",
    "links=[]\n",
    "for i in range(len(companies)):\n",
    "    query = 'site:linkedin.com/in/'+\" \" + names[i] +\" \"+ companies[i] \n",
    "    \n",
    "    print(\"Query to search:\",query)\n",
    "    person_name=names[i]\n",
    "    company_name=companies[i]\n",
    "    for url in search(query, tld=\"co.in\", num=1, stop=1,pause=5): \n",
    "        person_link=url\n",
    "        print(\"LinkedIn URL:\",person_link)\n",
    "        results.cell(row=i+2, column=col_name).value = person_name\n",
    "        results.cell(row=i+2, column=col_company_name).value = company_name\n",
    "        results.cell(row=i+2, column=col_person_link).value = person_link\n",
    "        links.append(person_link)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.save(filename='results_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"parameters.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining new variable passing two parameters\n",
    "writer = csv.writer(open(parameters.file_name, 'w'))\n",
    "\n",
    "# writerow() method to the write to the file object\n",
    "writer.writerow([\"Name\", \"Job_Title\",\"Previous_Job_title\",\"Honors_Awards\",\"Person_Location\",\"College\",\"Qualification\", \"Company\",\"CompanyIndustry\",\"Founded\",\"Person_URL\",\"Company_URL\",\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies the path to the chromedriver.exe\n",
    "driver = webdriver.Chrome('E:\\STUDY\\Practicum\\LinkedIn\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get method() will navigate to a page given by the URL address\n",
    "driver.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate email form by_class_name\n",
    "username = driver.find_element_by_id('username')\n",
    "\n",
    "\n",
    "# send_keys() to simulate key strokes\n",
    "username.send_keys(parameters.linkedin_username)\n",
    "# sleep for 0.5 seconds\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate password form by_class_name\n",
    "password = driver.find_element_by_id('password')\n",
    "\n",
    "# send_keys() to simulate key strokes\n",
    "password.send_keys(parameters.linkedin_password)\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# locate submit button by_id\n",
    "log_in_button = driver.find_element_by_class_name('login__form_action_container ')\n",
    "\n",
    "# .click() to mimic button click\n",
    "log_in_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsel import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.save(filename='results_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Staff Data Engineer', 'Company Name', 'Rubrik, Inc. Full-time', 'Dates Employed', 'Oct 2018 – Present', 'Employment Duration', '1 yr 8 mos', 'Location', 'Palo Alto, California', 'Architected and built ground up a Data Platform to cater to the following needs:', '1. Repository for all Product Telemetry data, Customer Interaction data, Business Transaction Data', '2. Provide compute and query capability to merge, transform and aggregate data', '3. Build data driven internal automation applications for purposes ranging from Notifications to Auto Provisioning of resources on demand', '4. Extract and present business Intelligence from the data to provide greater visibility across the business functions', '5. Support ML/AI use cases like Opportunity Scoring, Lead Scoring, Inventory Management etc.', '6. Enable self serve reporting and data ingestion', '7. Establish user profiles and enable data level and content level security across the platform', '8. Enable API driven architecture for data consumption on the Mobile Platform and expandable to applications beyond.', '', 'Data Store: Snowflake, AWS S3', 'Custom Data Integration: Python and Shell Scripting.', 'Data Pipelines created using Python and Shell Wrapper. Re-usable libraries written for S3 read-writes, Snowflake Bulk Loads, RDB reads, RestAPI reads, etc.', 'Package Integration Solution: Fivetran for Enterprise Applications with large object list like SFDC, Netsuite, etc.', 'BI: Tableau Online', 'Compute Platform: Elastic Compute, Kubernetes and Containers.', 'AWS EC2, Amazon EKS, Amazon ECS, AWS Lambda', 'Dev Tools: Github, DataGrip, JIRA', 'Data Transformation: SQL based DB Views, Python wrapper scripts to batch trigger data materialisation', 'Security: Row level Data security on Tableau, Tableau Content/Project level security via User Groups, DB Compute and Data Store Allocation based on DB Roles, Okta Auth for Snowflake and Tableau', '…', 'see more']\n",
      "[('Rubrik, Inc. Full-time', 'Staff Data Engineer')]\n",
      "['Company Name', 'VMware', 'Total Duration', '4 yrs 2 mos', 'Title', 'Senior Data Engineer', 'Full-time', 'Dates Employed', 'Oct 2017 – Oct 2018', 'Employment Duration', '1 yr 1 mo', 'Location', 'Palo Alto, California', 'EDW for CPBU SaaS.', '', 'Data Store: Amazon Redshift, AWS S3', 'BI: ModeAnalytics, Tableau', 'Data Integration: Python Scripts, Segment.ai', 'Compute: AWS EC2, AWS Lambda', 'CD/CI Tools: Github, ECR, Custom Python based script to do code Merge, Compile and Deploy', 'Other Services: AWS SNS, AWS SQS', '', 'Features:', '1. Automated SRE Notification Services to Customers on Planned Maintenance using HTML Templates, SQS, SNS and SQL based API services', '2. Customer 360 view. Lead to Service Consumption to Churn.', '3. ML/AI based Automation: Capacity Planning and Resource Allocation Prioritisation', '4. Post Purchase Adoption and Consumption reporting', '5. Up/Cross Sell Opportunities', '6. Funnel Conversions from Lead to Bookings to identify and optimise process and improve execution', '7. Uptime, Error Metrics to gauge Service Quality', '…', 'see more', 'Title', 'Sr Application Developer', 'Full-time', 'Dates Employed', 'Sep 2014 – Oct 2017', 'Employment Duration', '3 yrs 2 mos', 'Location', 'Palo Alto, California', '- EDW on SAP HANA', 'Ground up build of Custom SAP HANA EDW solution with Virtual Data Models created across subject areas. Multilevel and complex node built keeping single source of truth for all kinds of reporting. Models were built with a lot of thought put into the designs first, for optimum performance and query pruning.', 'Implemented data level security implementation based on user roles and their data auth set across dimensional values and levels. BI using SAP Business Objects and Tableau.', '', '- Enterprise Data Warehouse Migration from Informatica-Oracle to GPSQL-Greenplum', 'This was a mammoth project to completely migrate the EDW from Oracle DB to Greenplum DB in a span of 10months time, design to production.', 'Extraction/Workflow: Informatica, Transformation: GPSQL, Datastore: Greenplum', '', '- Subscription Services Reporting', 'Monthly Recurring Revenue Reporting', 'Customer Churn Reporting', 'Trial to Purchase Conversions', '', '- Sales Planning Reporting', 'Link customer data within Salesforce to EBS', 'Implement categorization rules on Bookings.', \"Created a custom solution for Categorization rules to be defined on IBM-ODM. Run extractions on ODM to consume the rules, transform to SQL's and apply to millions of records multiple times a day.\", 'Designed single OBIEE RPD model for Pipeline-Booking-Targets-Commisions.', 'Provide centralized data to Anaplan for Sales Planning and Quota and consume from Anaplan for all Operational Reporting.', '', '- Sales Mobile Application', 'Provide a near real-time Customer Relationship with VMware to Salesreps on the move', 'Mobile Platform built on top of Elasticsearch', 'Continuous data flow of Pipelines, Support Cases and Real time Customer Bookings', '…', 'see more']\n",
      "[('Rubrik, Inc. Full-time', 'Staff Data Engineer'), ('VMware', 'Senior Data Engineer')]\n"
     ]
    }
   ],
   "source": [
    "col_name=13\n",
    "curr_title=2\n",
    "prev_title=3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(links)): #Iterate loop for number of links\n",
    "    j=0\n",
    "    driver.get(links[i]) #Landed on LinkedIn profile of the person\n",
    "    time.sleep(2.5) #Sleep to show that its not automated\n",
    "    #text=driver.page_source \n",
    "    sel = Selector(text=driver.page_source) \n",
    "    person_location = sel.xpath('//*[starts-with(@class, \"t-16 t-black t-normal inline-block\")]/text()').extract_first()\n",
    "    #title=sel.xpath('//*[starts-with(@class, \"t-14 t-black t-bold\")]/text()').extract_first()\n",
    "    experience = driver.find_elements_by_css_selector('#experience-section .pv-profile-section')\n",
    "    employer_title=[]\n",
    "    for item in experience:\n",
    "        j+=1\n",
    "        if(j==3):\n",
    "            break\n",
    "        else:\n",
    "#             print(\"Experience: \",j)\n",
    "            a=item.text.split('\\n') \n",
    "            \n",
    "            if(a[0]==\"Company Name\"):\n",
    "                employer_title.append((a[1],a[5]))\n",
    "            else:\n",
    "                employer_title.append((a[2],a[0]))\n",
    "        print(employer_title)\n",
    "    for k in range(len(employer_title)):\n",
    "        results.cell(row=i+2, column=curr_title).value = employer_title[0][1]\n",
    "        results.cell(row=i+2, column=prev_title).value = employer_title[1][1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.save(filename='results_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
